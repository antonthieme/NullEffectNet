{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import sys\n",
    "import pandas as pd\n",
    "import ast\n",
    "import pickle\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, precision_recall_curve\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "sys.path.append('../src/null-effect-net')\n",
    "import utils\n",
    "import models\n",
    "import dataset\n",
    "import train_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_utils.set_seed(42)\n",
    "\n",
    "id_map_df = pd.read_csv('../data/id_mappings/gene_ref.tsv', sep='\\t')\n",
    "\n",
    "with open('../data/embeddings.pkl', 'rb') as f:\n",
    "    node_features_df = pickle.load(f)\n",
    "\n",
    "node_features_df['Concat Embedding'] = node_features_df['PINNACLE Embedding'] + node_features_df['SubCell Embedding'] + node_features_df['ESM Embedding']\n",
    "\n",
    "train_df = pd.read_csv('../data/perturbation_screens/e_distance/train.csv', index_col=0)\n",
    "test_df = pd.read_csv('../data/perturbation_screens/e_distance/test.csv', index_col=0)\n",
    "\n",
    "active_nodes_df = pd.read_csv('../data/expression_reference/expression_reference.csv', index_col=0)\n",
    "\n",
    "G = nx.read_edgelist('../data/networks/global_ppi_edgelist.txt')\n",
    "\n",
    "ensembl_to_node = dict(zip(id_map_df['Ensembl gene ID'], id_map_df['Approved symbol']))\n",
    "node_to_ensembl = dict(zip(id_map_df['Approved symbol'], id_map_df['Ensembl gene ID']))\n",
    "\n",
    "G = nx.relabel_nodes(G, node_to_ensembl)\n",
    "\n",
    "# Get set of nodes that have features\n",
    "valid_nodes = set(node_features_df['Ensembl ID'])\n",
    "\n",
    "# Remove nodes from G that are not in valid_nodes\n",
    "G.remove_nodes_from([n for n in list(G.nodes) if n not in valid_nodes])\n",
    "\n",
    "node_to_idx = {node: idx for idx, node in enumerate(G.nodes())}\n",
    "\n",
    "train_df = train_df[train_df['Target'].isin(G.nodes())]\n",
    "test_df = test_df[test_df['Target'].isin(G.nodes())]\n",
    "\n",
    "# Convert to edge_index format\n",
    "data = from_networkx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_df['Concatenated Embedding'] = node_features_df['PINNACLE Embedding'] + node_features_df['SubCell Embedding'] + node_features_df['ESM Embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_df.drop(['Concat Embedding', 'Concatenated Embedding'], axis=1, inplace=True)\n",
    "node_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_vector(v, max_len):\n",
    "    padded = np.zeros(max_len, dtype=np.float32)\n",
    "    padded[:len(v)] = v\n",
    "    return padded\n",
    "\n",
    "def make_padded_set(row, max_len):\n",
    "    return np.stack([\n",
    "        pad_vector(row['ESM Embedding'], max_len),\n",
    "        pad_vector(row['SubCell Embedding'], max_len),\n",
    "        pad_vector(row['PINNACLE Embedding'], max_len)\n",
    "    ])  # shape: (3, max_len)\n",
    "\n",
    "all_lengths = [\n",
    "    len(vec)\n",
    "    for _, row in node_features_df.iterrows()\n",
    "    for vec in [row['ESM Embedding'], row['SubCell Embedding'], row['PINNACLE Embedding']]\n",
    "]\n",
    "max_len = max(all_lengths)\n",
    "\n",
    "node_features_df['Set Embedding'] = node_features_df.apply(\n",
    "    lambda row: make_padded_set(row, max_len),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "data = from_networkx(G)\n",
    "\n",
    "set_tensor = torch.stack([\n",
    "    torch.tensor(node_features_df.set_index('Ensembl ID').loc[idx]['Set Embedding'])\n",
    "    for idx in G.nodes()\n",
    "])  # shape: (num_nodes, 3, max_len)\n",
    "\n",
    "# Mask where entries are non-zero (i.e., not padded)\n",
    "mask_tensor = (set_tensor != 0).any(dim=-1).to(torch.float32)  # shape: (num_nodes, 3)\n",
    "\n",
    "data.set_features = set_tensor.to(torch.float32)\n",
    "data.set_mask = mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datasets\n",
    "train_dataset = dataset.GNNDataset(\n",
    "    train_df,\n",
    "    active_nodes_df,\n",
    "    node_features_df,\n",
    "    node_to_idx,\n",
    "    device=device\n",
    ")\n",
    "val_dataset = dataset.GNNDataset(\n",
    "    test_df,\n",
    "    active_nodes_df,\n",
    "    node_features_df,\n",
    "    node_to_idx,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Build dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=dataset.collate_function_gnn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=dataset.collate_function_gnn)\n",
    "\n",
    "# Initialize model and optimizer fresh for each fold\n",
    "input_dim = len(node_features_df['Set Embedding'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.GNNAttentionClassifier(\n",
    "    input_dim,       \n",
    "    pool_hidden_dim=512,\n",
    "    pool_out_dim=128,\n",
    "    gcn_hidden_dim=128,\n",
    "    gcn_out_dim=32, \n",
    "    neg_weight=3.0,\n",
    "    only_active=False,\n",
    "    return_attn=False\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "\n",
    "best_val_auc = 0.0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\n----- Epoch {epoch}/{num_epochs} -----\")\n",
    "    train_metrics = train_utils.train_one_epoch_gnn(model, data, train_loader, optimizer, device)\n",
    "    val_metrics, y_true_val, y_pred_val, y_prob_val = train_utils.evaluate_gnn(model, data, val_loader, device)\n",
    "\n",
    "    if val_metrics['auc'] > best_val_auc:\n",
    "        best_val_auc = val_metrics['auc']\n",
    "        best_precision = val_metrics['precision']\n",
    "        best_recall = val_metrics['recall']\n",
    "        best_f1 = val_metrics['f1']\n",
    "        train_utils.save_model(model, '../models', experiment=f'attention_analysis')\n",
    "        print(f\"New best model saved with AUC: {best_val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.GNNAttentionClassifier(\n",
    "    input_dim,       \n",
    "    pool_hidden_dim=256,\n",
    "    pool_out_dim=128,\n",
    "    gcn_hidden_dim=256,\n",
    "    gcn_out_dim=128, \n",
    "    neg_weight=3.0,\n",
    "    only_active=False\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-5)\n",
    "\n",
    "best_val_auc = 0.0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\n----- Epoch {epoch}/{num_epochs} -----\")\n",
    "    train_metrics = train_utils.train_one_epoch_gnn(model, data, train_loader, optimizer, device)\n",
    "    val_metrics, y_true_val, y_pred_val, y_prob_val = train_utils.evaluate_gnn(model, data, val_loader, device)\n",
    "\n",
    "    if val_metrics['auc'] > best_val_auc:\n",
    "        best_val_auc = val_metrics['auc']\n",
    "        best_precision = val_metrics['precision']\n",
    "        best_recall = val_metrics['recall']\n",
    "        best_f1 = val_metrics['f1']\n",
    "        train_utils.save_model(model, '../models', experiment=f'attention_analysis_second_hyperparameters')\n",
    "        print(f\"New best model saved with AUC: {best_val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, y_true, y_pred, y_prob, attn_data = train_utils.evaluate_gnn_with_attention(model, data, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = attn_data[\"attn_weights\"]       # shape: (N, set_len)\n",
    "query_nodes = attn_data[\"query_nodes\"]         # shape: (N,)\n",
    "set_masks = attn_data[\"set_masks\"]             # shape: (N, set_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights = attn_weights[0:9305]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_masks = set_masks[0:9305]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(node_features_df['Set Embedding'][0][0])\n",
    "model = train_utils.load_model(\n",
    "    models.GNNAttentionClassifier, \n",
    "    input_dim=input_dim, \n",
    "    pool_hidden_dim=256,\n",
    "    pool_out_dim=128,\n",
    "    gcn_hidden_dim=256,\n",
    "    gcn_out_dim=128, \n",
    "    neg_weight=3.0,\n",
    "    only_active=False, \n",
    "    path='../models/attention_analysis_second_hyperparameters/GNNAttentionClassifier/checkpoint_05_03-22_23.pt')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(attn_weights.numpy(), columns=[\"ESM\", \"SubCell\", \"PINNACLE\"])\n",
    "\n",
    "# Optional: Normalize each row to sum to 1 (if not already softmaxed)\n",
    "#df = df.div(df.sum(axis=1), axis=0)\n",
    "\n",
    "# Plot clustermap\n",
    "sns.clustermap(df, metric=\"euclidean\", method=\"ward\", cmap=\"viridis\", standard_scale=1)\n",
    "\n",
    "plt.title(\"Node Attention Clustermap\")\n",
    "plt.savefig('../figures/attention_analysis/node_attention_clustermap.svg', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_node = {idx: node for idx, node in zip(node_to_idx.values(), node_to_idx.keys())}\n",
    "df['Ensembl ID'] = df.index.to_series().map(idx_to_node)\n",
    "df['Symbol'] = df['Ensembl ID'].map(ensembl_to_node)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df[['ESM', 'SubCell', 'PINNACLE']])\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)  # Specify the number of clusters\n",
    "df['KMeans_Cluster'] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['KMeans_Cluster'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sym in list(df[df['KMeans_Cluster'] == 4]['Symbol']):\n",
    "    print(sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
